{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import lxml\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fonction pour DL un pdf (ce serait bien d'ajouter une fonction pour diminuer la taille des fichier)\n",
    "def download_file(download_url, filename):\n",
    "    response = urllib.request.urlopen(download_url)    \n",
    "    file = open(filename + \".pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creer un csv contenant toutes les url des pages des SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.gesteau.fr/sage/adour-amont#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/adour-aval#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/agly#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/agout#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/aisne-vesle-suippe#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/alagnon#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/allan#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/allier-aval#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/arc-provencal#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/ardeche#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/argens#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/argoat-tregor-goelo#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/arguenon-baie-de-la-fresnaye#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/armancon#edit-group-sage-documents\n",
      "https://www.gesteau.fr/sage/arroux-bourbince#edit-group-sage-documents\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file = open('C:/RD/_SCRAPING/output/output.csv', 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['url'])\n",
    "\n",
    "for page in range(0,1):\n",
    "    \n",
    "    url = 'https://www.gesteau.fr/rechercher/sage?title=&field_comite_target_id=&field_sage_etat_avancement_value=All&field_sage_sous_etat_avancement_value=All&field_sage_sdage2_value=All&gesteau_field_rw_target_id=&gesteau_field_cw_target_id=&gesteau_field_tw_target_id=&gesteau_field_lw_target_id=&gesteau_paragraph_field_gw=&gesteau_paragraph_field_communes=&rech_admin_sage=&field_milieu_target_id=&type_masse_d_eau=&rech_masse_d_eau=&field_sage_enjeux_value=&field_themes_enjeux_target_id=All&field_sage_regles_value=&field_theme_regle_target_id=All&gesteau_field_communes=&page='\n",
    "    url2 = 'https://www.gesteau.fr'\n",
    "    req = requests.get(url+str(page))\n",
    "    soup = bs(req.text, \"lxml\")\n",
    "        \n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    for td in table.find_all('td') :\n",
    "        for anchor in td.find_all('a'):\n",
    "            \n",
    "            href = anchor['href'].strip()\n",
    "            \n",
    "            link = url2+href+'#edit-group-sage-documents'\n",
    "            print (link)\n",
    "            writer.writerow([link])\n",
    "            \n",
    "            \n",
    "file.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec le csv créé accèder à toutes les pages pour extraire le contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder_already_exists\n",
      "Adour amont Arrêtés et délibérations https://www.gesteau.fr/sites/default/files/gesteau/content_files/document/arrete-perimetre14-09-2004.pdf\n",
      "C:/RD/_SCRAPING/output/_documents/Adour amont/Arrêtés et délibérations/\n",
      "Adour amont pas de documents\n",
      "folder_already_exists\n",
      "Adour aval Arrêtés et délibérations https://www.gesteau.fr/sites/default/files/gesteau/content_files/document/ap_perimetre_sage_adour_aval.pdf\n",
      "C:/RD/_SCRAPING/output/_documents/Adour aval/Arrêtés et délibérations/\n",
      "Adour aval pas de documents\n",
      "folder_already_exists\n",
      "Agly Arrêtés et délibérations https://www.gesteau.fr/sites/default/files/gesteau/content_files/document/doc_SAGE06001-1219325152.pdf\n",
      "C:/RD/_SCRAPING/output/_documents/Agly/Arrêtés et délibérations/\n",
      "Agly pas de documents\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/RD/_SCRAPING/output/output.csv\") as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    for link in reader:  \n",
    "        req = requests.get(link['url'])\n",
    "        \n",
    "        soup = bs(req.text, \"lxml\")\n",
    "        \n",
    "        sage_name= soup.title.string.replace(\" | Gest'eau\", \"\")\n",
    "        dir = \"C:/RD/_SCRAPING/output/_documents/\"+sage_name.replace(\" | Gest'eau\", \"\")\n",
    "        \n",
    "        if os.path.exists(dir):\n",
    "            print('folder_already_exists')\n",
    "        else :\n",
    "            os.mkdir(dir)\n",
    "        try:\n",
    "            for docs in soup.find_all('div',  class_=\"item-list\"):\n",
    "                #print(sage_name,docs)\n",
    "                \n",
    "                    #print('type_doc: ',type_doc)\n",
    "                    for anchor in docs.find_all('a', href = True):\n",
    "                        doc_type= anchor.find_previous('h3').text.strip()\n",
    "                        dir2=\"C:/RD/_SCRAPING/output/_documents/\"+sage_name+'/'+doc_type\n",
    "\n",
    "                        if os.path.exists(dir2):\n",
    "\n",
    "                            ## let's get those .pdf\n",
    "                            req_pdf = requests.get('https://www.gesteau.fr'+anchor['href'])\n",
    "                        \n",
    "                            soup_pdf = bs(req_pdf.text, \"lxml\")\n",
    "                        \n",
    "                            for pdf in soup_pdf.find_all('span',class_=\"file file--mime-application-pdf file--application-pdf\"):\n",
    "                            \n",
    "                                for file in pdf.find_all('a', href = True):\n",
    "                                    dir_pdf=\"C:/RD/_SCRAPING/output/_documents/\"+sage_name+'/'+doc_type+'/'\n",
    "                                    print(sage_name, doc_type, file['href'])\n",
    "                                    print(dir_pdf)\n",
    "                                    download_file(file['href'], dir_pdf+file.get_text() )\n",
    "                                time.sleep(0.5)\n",
    "                                \n",
    "                        else :\n",
    "                            # if the folder doesn't exists then make it\n",
    "                            os.mkdir(dir2)\n",
    "                            ## let's get those .pdf\n",
    "                            req_pdf = requests.get('https://www.gesteau.fr'+anchor['href'])\n",
    "                        \n",
    "                            soup_pdf = bs(req_pdf.text, \"lxml\")\n",
    "                        \n",
    "                            for pdf in soup_pdf.find_all('span',class_=\"file file--mime-application-pdf file--application-pdf\"):\n",
    "                            \n",
    "                                for file in pdf.find_all('a', href = True):\n",
    "                                    dir_pdf=\"C:/RD/_SCRAPING/output/_documents/\"+sage_name+'/'+doc_type+'/'\n",
    "                                   \n",
    "                                    print(sage_name, doc_type, file['href'])\n",
    "                                    print(dir_pdf)\n",
    "                                    download_file(file['href'], dir_pdf+file.get_text())\n",
    "                                time.sleep(0.5)\n",
    "\n",
    "                        \n",
    "                        \n",
    "        except: \n",
    "            print(sage_name,'pas de documents')\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/RD/_SCRAPING/output/output.csv\") as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    for link in reader:  \n",
    "        req = requests.get(link['url'])\n",
    "        \n",
    "        soup = bs(req.text, \"lxml\")\n",
    "        \n",
    "        sage_name= soup.title.string.replace(\" | Gest'eau\", \"\")\n",
    "        dir = \"C:/RD/_SCRAPING/output/_documents/\"+sage_name.replace(\" | Gest'eau\", \"\")\n",
    "        \n",
    "        if os.path.exists(dir):\n",
    "            print('folder_already_exists')\n",
    "        else :\n",
    "            os.mkdir(dir)\n",
    "        try:\n",
    "            for docs in soup.find_all('div',  class_=\"item-list\"):\n",
    "                #print(sage_name,docs)\n",
    "                \n",
    "                    #print('type_doc: ',type_doc)\n",
    "                    for anchor in docs.find_all('a', href = True):\n",
    "                        doc_type= anchor.find_previous('h3').text.strip()\n",
    "                        sage_name.replace(\" | Gest'eau\", \"\")\n",
    "                        dir2=\"C:/RD/_SCRAPING/output/_documents/\"+sage_name+'/'+doc_type\n",
    "                        #print(dir2)\n",
    "                        if os.path.exists(dir2):\n",
    "\n",
    "                            ## let's get those .pdf\n",
    "                            req_pdf = requests.get('https://www.gesteau.fr'+anchor['href'])\n",
    "                        \n",
    "                            soup_pdf = bs(req_pdf.text, \"lxml\")\n",
    "                        \n",
    "                            for pdf in soup_pdf.find_all('span',class_=\"file file--mime-application-pdf file--application-pdf\"):\n",
    "                            \n",
    "                                for file in pdf.find_all('a', href = True):\n",
    "                                    dir_pdf=\"C:/RD/_SCRAPING/output/_documents/\"+sage_name+'/'+doc_type+'/'\n",
    "                                    print(sage_name, doc_type, file['href'])\n",
    "                                    print(dir_pdf)\n",
    "                                    download_file(file['href'], dir_pdf+file.get_text() )\n",
    "                                time.sleep(0.5)\n",
    "                        else :\n",
    "                            # if the folder doesn't exists then make it\n",
    "                            os.mkdir(dir2)\n",
    "                            ## let's get those .pdf\n",
    "                            req_pdf = requests.get('https://www.gesteau.fr'+anchor['href'])\n",
    "                        \n",
    "                            soup_pdf = bs(req_pdf.text, \"lxml\")\n",
    "                        \n",
    "                            for pdf in soup_pdf.find_all('span',class_=\"file file--mime-application-pdf file--application-pdf\"):\n",
    "                            \n",
    "                                for file in pdf.find_all('a', href = True):\n",
    "                                    dir_pdf=\"C:/RD/_SCRAPING/output/_documents/\"+sage_name+'/'+doc_type+'/'\n",
    "                                   \n",
    "                                    print(sage_name, doc_type, file['href'])\n",
    "                                    print(dir_pdf)\n",
    "                                    download_file(file['href'], dir_pdf+file.get_text())\n",
    "                                time.sleep(0.5)\n",
    "\n",
    "                        \n",
    "                        \n",
    "        except: \n",
    "            print(sage_name,'pas de documents')\n",
    "\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap",
   "language": "python",
   "name": "scrap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
